# _**General URLS and data**_

- ### Markdown Documentation 
>https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax

- ### Amazing Diff Tool
>https://www.w3docs.com/tools/code-diff/

- ### Azure Notebooks for ML Train
>https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks?view=azureml-api-2

- ### YouTube Video Object Detection Implementation from Jetson Inference
>https://www.youtube.com/watch?v=mB025B7KpeE

#
# _**Depth Analysis**_ 
## 1. Libraries Installation

>python -m venv depthanalysis

>depthanalysis\Scripts\activate

>pip install geocoder

>pip install wheel

>pip install torch

>pip install pyttsx3

>pip install numpy

>pip install opencv-python

>pip install scipy
#
## Important Links
- Orignal Model Project Imported from
>https://mannequin-depth.github.io/

>https://github.com/google/mannequinchallenge

>https://google.github.io/mannequinchallenge/www/index.html
- Another side project using same model
>https://github.com/arvkr/BodyScan

- Google Collab Training Notebook
>https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb

- Another GitHub Repo about pix2pix model
>https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix

- A-EYE for the Blind
>https://www.youtube.com/watch?v=ZvOr_FAJeDI

>https://devpost.com/software/a-eye-for-the-blind#updates

>https://github.com/saranggoel/A-Eye_For_the_Blind

- Neural network depth extraction from single image for blender 3d or other use
>https://www.youtube.com/watch?v=9ZjmY6EFr6E

- Learning Depths of Moving People by Watching Frozen People
>https://www.youtube.com/watch?v=fj_fK74y5_0
